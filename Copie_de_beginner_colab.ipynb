{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RouguiBa/projet_initiation_recherche/blob/main/Copie_de_beginner_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pPbS8n4taNn",
        "outputId": "978a0ad8-362b-4d0d-ce9b-462bfe0b153d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36EdAGhThQov"
      },
      "source": [
        "# Build, train and evaluate models with TensorFlow Decision Forests\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/decision-forests/blob/main/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/decision-forests/blob/main/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/decision-forests/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvvDY0LVhuaW"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Decision Forests (DF) are a large family of Machine Learning algorithms for\n",
        "supervised classification, regression and ranking. As the name suggests, DFs use\n",
        "decision trees as a building block. Today, the two most popular DF training\n",
        "algorithms are [Random Forests](https://en.wikipedia.org/wiki/Random_forest) and\n",
        "[Gradient Boosted Decision Trees](https://en.wikipedia.org/wiki/Gradient_boosting). Both algorithms are ensemble techniques that use multiple decision trees, but differ on how they do it.\n",
        "\n",
        "TensorFlow Decision Forests (TF-DF) is a library for the training,\n",
        "evaluation, interpretation and inference of Decision Forest models.\n",
        "\n",
        "In this tutorial, you will learn how to:\n",
        "\n",
        "1.  Train a binary classification Random Forest on a dataset containing numerical, categorical and missing features.\n",
        "1.  Evaluate the model on a test dataset.\n",
        "1.  Prepare the model for\n",
        "    [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n",
        "1.  Examine the overall structure of the model and the importance of each feature.\n",
        "1.  Re-train the model with a different learning algorithm (Gradient Boosted Decision Trees).\n",
        "1.  Use a different set of input features.\n",
        "1.  Change the hyperparameters of the model.\n",
        "1.  Preprocess the features.\n",
        "1.  Train a model for regression.\n",
        "1.  Train a model for ranking.\n",
        "\n",
        "Detailed documentation is available in the [user manual](https://github.com/tensorflow/decision-forests/tree/main/documentation).\n",
        "The [example directory](https://github.com/tensorflow/decision-forests/tree/main/examples) contains other end-to-end examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK9tCTcwqq4k"
      },
      "source": [
        "## Installing TensorFlow Decision Forests\n",
        "\n",
        "Install TF-DF by running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pa1Pf37RhEYN",
        "outputId": "dd281a9b-56bc-4f77-fdbd-1591c1012094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wurlitzer in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.21.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (0.38.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.5)\n",
            "Collecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (4.1.1)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.28.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (14.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow~=2.11.0->tensorflow_decision_forests) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow_decision_forests) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-decision-forests\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-decision-forests-1.1.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZGda2dOe-hH"
      },
      "source": [
        "[Wurlitzer](https://pypi.org/project/wurlitzer/) is needed to display the detailed training logs in Colabs (when using `verbose=2` in the model constructor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lk26uBSCe8Du",
        "outputId": "4dfb1a51-77cc-428a-e62d-4232fb6f56a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-3.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wurlitzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oinwbhXlggd"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "52W45tmDjD64"
      },
      "outputs": [],
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LPPwWxYxtDM"
      },
      "source": [
        "The hidden code cell limits the output height in colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AhqJz3VmQM-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import display as ipy_display\n",
        "\n",
        "# Some of the model training logs can cover the full\n",
        "# screen if not compressed to a smaller viewport.\n",
        "# This magic allows setting a max height for a cell.\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  ipy_display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8gVQ-txtjFU4",
        "outputId": "4b30c91e-2fbe-4129-ddfe-9d6994ac3c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TensorFlow Decision Forests v1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Check the version of TensorFlow Decision Forests\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRtRECujKeu"
      },
      "source": [
        "## Training a Random Forest model\n",
        "\n",
        "In this section, we train, evaluate, analyse and export a binary classification Random Forest trained on the [Palmer's Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) dataset.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png\" width=\"150\"/></center>\n",
        "\n",
        "**Note:** The dataset was exported to a csv file without pre-processing: `library(palmerpenguins); write.csv(penguins, file=\"penguins.csv\", quote=F, row.names=F)`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qsSU1RfmNiP"
      },
      "source": [
        "### Load the dataset and convert it in a tf.Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nJ5igfElg2I"
      },
      "source": [
        "This dataset is very small (300 examples) and stored as a .csv-like file. Therefore, use Pandas to load it.\n",
        "\n",
        "**Note:** Pandas is practical as you don't have to type in name of the input features to load them. For larger datasets (>1M examples), using the\n",
        "[TensorFlow Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to read the files may be better suited.\n",
        "\n",
        "Let's assemble the dataset into a csv file (i.e. add the header), and load it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "44Jq6g_mJFmj",
        "outputId": "fa1a5920-7ac5-41a1-f88c-8f09c378b178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           geometrie territoire      symbo  \\\n",
              "0  0106000080010000000103000080010000000D00000066...        FXX  BATI_QQUE   \n",
              "1  010600008001000000010300008001000000060000009A...        FXX  BATI_QQUE   \n",
              "2  0106000080010000000103000080010000000500000033...        FXX  BATI_QQUE   \n",
              "\n",
              "   hauteur isole niveau  surface  density_building_500m  acces  perimetre  \\\n",
              "0     8.20     f     n0   142.78            2813.859394    0.0  60.511225   \n",
              "1     7.60     f     n0    66.91            2802.400238    0.0  32.800689   \n",
              "2     1.25     f     n0     3.40            2750.197417    0.0   7.496929   \n",
              "\n",
              "   ...  plus_proche_bat  p_max_1km  ind_forme_1km  s_max_2km  p_max_2km  \\\n",
              "0  ...         0.000000  497.65308       0.001510   11500.27  497.65308   \n",
              "1  ...         0.000000  497.65308       0.000383   11500.27  497.65308   \n",
              "2  ...         0.921954  497.65308       0.000004   11500.27  497.65308   \n",
              "\n",
              "   ind_forme_2km  s_max_5km    p_max_5km  ind_forme_5km  r1  \n",
              "0       0.001510   20263.17  1060.116642       0.000402   f  \n",
              "1       0.000383   20263.17  1060.116642       0.000102   f  \n",
              "2       0.000004   20263.17  1060.116642       0.000001   f  \n",
              "\n",
              "[3 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42a71bdf-30c5-4fb6-8b9f-149e80f45cf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geometrie</th>\n",
              "      <th>territoire</th>\n",
              "      <th>symbo</th>\n",
              "      <th>hauteur</th>\n",
              "      <th>isole</th>\n",
              "      <th>niveau</th>\n",
              "      <th>surface</th>\n",
              "      <th>density_building_500m</th>\n",
              "      <th>acces</th>\n",
              "      <th>perimetre</th>\n",
              "      <th>...</th>\n",
              "      <th>plus_proche_bat</th>\n",
              "      <th>p_max_1km</th>\n",
              "      <th>ind_forme_1km</th>\n",
              "      <th>s_max_2km</th>\n",
              "      <th>p_max_2km</th>\n",
              "      <th>ind_forme_2km</th>\n",
              "      <th>s_max_5km</th>\n",
              "      <th>p_max_5km</th>\n",
              "      <th>ind_forme_5km</th>\n",
              "      <th>r1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0106000080010000000103000080010000000D00000066...</td>\n",
              "      <td>FXX</td>\n",
              "      <td>BATI_QQUE</td>\n",
              "      <td>8.20</td>\n",
              "      <td>f</td>\n",
              "      <td>n0</td>\n",
              "      <td>142.78</td>\n",
              "      <td>2813.859394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.511225</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>11500.27</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>20263.17</td>\n",
              "      <td>1060.116642</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>010600008001000000010300008001000000060000009A...</td>\n",
              "      <td>FXX</td>\n",
              "      <td>BATI_QQUE</td>\n",
              "      <td>7.60</td>\n",
              "      <td>f</td>\n",
              "      <td>n0</td>\n",
              "      <td>66.91</td>\n",
              "      <td>2802.400238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.800689</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>11500.27</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>20263.17</td>\n",
              "      <td>1060.116642</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0106000080010000000103000080010000000500000033...</td>\n",
              "      <td>FXX</td>\n",
              "      <td>BATI_QQUE</td>\n",
              "      <td>1.25</td>\n",
              "      <td>f</td>\n",
              "      <td>n0</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2750.197417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.496929</td>\n",
              "      <td>...</td>\n",
              "      <td>0.921954</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>11500.27</td>\n",
              "      <td>497.65308</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>20263.17</td>\n",
              "      <td>1060.116642</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42a71bdf-30c5-4fb6-8b9f-149e80f45cf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42a71bdf-30c5-4fb6-8b9f-149e80f45cf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42a71bdf-30c5-4fb6-8b9f-149e80f45cf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Download the dataset\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"/content/drive/MyDrive/pire/bati_surf_n0.csv\")\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23AewWT1lkIK"
      },
      "source": [
        "The dataset contains a mix of numerical (e.g. `bill_depth_mm`), categorical\n",
        "(e.g. `island`) and missing features. TF-DF supports all these feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding, normalization or extra `is_present` feature.\n",
        "\n",
        "Labels are a bit different: Keras metrics expect integers. The label (`species`) is stored as a string, so let's convert it into an integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uO_jz2sj0IBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5def8c4-14c0-466d-c86e-7fc380e6497b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes: ['f', 't']\n"
          ]
        }
      ],
      "source": [
        "# Encode the categorical labels as integers.\n",
        "#\n",
        "# Details:\n",
        "# This stage is necessary if your classification label is represented as a\n",
        "# string since Keras expects integer classification labels.\n",
        "# When using `pd_dataframe_to_tf_dataset` (see below), this step can be skipped.\n",
        "\n",
        "# Name of the label column.\n",
        "label = \"r1\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwJjLFhbtozI"
      },
      "source": [
        "Next split the dataset into training and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u7DEIxn2oB3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5571de9b-2265-4b6d-96dc-f4ceff2de904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "267232 examples in training, 114388 examples for testing.\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWq7uQcCuBzO"
      },
      "source": [
        "And finally, convert the pandas dataframe (`pd.Dataframe`) into tensorflow datasets (`tf.data.Dataset`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qtXgUBKluTX0"
      },
      "outputs": [],
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRKLWIWNuOZ1"
      },
      "source": [
        "**Notes:** Recall that `pd_dataframe_to_tf_dataset` converts string labels to integers if necessary.\n",
        "\n",
        "If you want to create the `tf.data.Dataset` yourself, there are a couple of things to remember:\n",
        "\n",
        "- The learning algorithms work with a one-epoch dataset and without shuffling.\n",
        "- The batch size does not impact the training algorithm, but a small value might slow down reading the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYAoyfYtqHG4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xete-FbuqJCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ea6540ed-4662-4f28-ae34-af7ec209ef9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmpwjm4p8t5 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'geometrie': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'territoire': <tf.Tensor 'data_20:0' shape=(None,) dtype=string>, 'symbo': <tf.Tensor 'data_19:0' shape=(None,) dtype=string>, 'hauteur': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'isole': <tf.Tensor 'data_8:0' shape=(None,) dtype=string>, 'niveau': <tf.Tensor 'data_9:0' shape=(None,) dtype=string>, 'surface': <tf.Tensor 'data_18:0' shape=(None,) dtype=float64>, 'density_building_500m': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'acces': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'perimetre': <tf.Tensor 'data_13:0' shape=(None,) dtype=float64>, 'id': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 's_max_1km': <tf.Tensor 'data_15:0' shape=(None,) dtype=float64>, 'plus_proche_bat': <tf.Tensor 'data_14:0' shape=(None,) dtype=float64>, 'p_max_1km': <tf.Tensor 'data_10:0' shape=(None,) dtype=float64>, 'ind_forme_1km': <tf.Tensor 'data_5:0' shape=(None,) dtype=float64>, 's_max_2km': <tf.Tensor 'data_16:0' shape=(None,) dtype=float64>, 'p_max_2km': <tf.Tensor 'data_11:0' shape=(None,) dtype=float64>, 'ind_forme_2km': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>, 's_max_5km': <tf.Tensor 'data_17:0' shape=(None,) dtype=float64>, 'p_max_5km': <tf.Tensor 'data_12:0' shape=(None,) dtype=float64>, 'ind_forme_5km': <tf.Tensor 'data_7:0' shape=(None,) dtype=float64>}\n",
            "Label: Tensor(\"data_21:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized tensor features:\n",
            " {'geometrie': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_2:0' shape=(None,) dtype=string>), 'territoire': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_20:0' shape=(None,) dtype=string>), 'symbo': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_19:0' shape=(None,) dtype=string>), 'hauteur': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'isole': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_8:0' shape=(None,) dtype=string>), 'niveau': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_9:0' shape=(None,) dtype=string>), 'surface': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'density_building_500m': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'acces': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'perimetre': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'id': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 's_max_1km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'plus_proche_bat': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'p_max_1km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'ind_forme_1km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>), 's_max_2km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_10:0' shape=(None,) dtype=float32>), 'p_max_2km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_11:0' shape=(None,) dtype=float32>), 'ind_forme_2km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_12:0' shape=(None,) dtype=float32>), 's_max_5km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_13:0' shape=(None,) dtype=float32>), 'p_max_5km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_14:0' shape=(None,) dtype=float32>), 'ind_forme_5km': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_15:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:00:08.573478. Found 267232 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training get stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 2022-12-07T14:05:17.696687723+00:00 kernel.cc:814] Start Yggdrasil model training\n",
            "[INFO 2022-12-07T14:05:17.69685374+00:00 kernel.cc:815] Collect training examples\n",
            "[INFO 2022-12-07T14:05:17.696961085+00:00 kernel.cc:423] Number of batches: 268\n",
            "[INFO 2022-12-07T14:05:17.696971525+00:00 kernel.cc:424] Number of examples: 267232\n",
            "[INFO 2022-12-07T14:05:19.243874689+00:00 data_spec_inference.cc:303] 267232 item(s) have been pruned (i.e. they are considered out of dictionary) for the column geometrie (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO 2022-12-07T14:05:19.531046181+00:00 data_spec_inference.cc:303] 6 item(s) have been pruned (i.e. they are considered out of dictionary) for the column symbo (33 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO 2022-12-07T14:05:19.796045852+00:00 kernel.cc:837] Training dataset:\n",
            "Number of records: 267232\n",
            "Number of columns: 22\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 16 (72.7273%)\n",
            "\tCATEGORICAL: 6 (27.2727%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 16 (72.7273%)\n",
            "\t0: \"acces\" NUMERICAL num-nas:77543 (29.0171%) mean:0.304952 min:0 max:4 sd:0.764921\n",
            "\t1: \"density_building_500m\" NUMERICAL mean:527.466 min:0 max:3446.66 sd:556.565\n",
            "\t3: \"hauteur\" NUMERICAL num-nas:79 (0.0295623%) mean:4.62254 min:0 max:39.6 sd:2.15231\n",
            "\t4: \"id\" NUMERICAL mean:191176 min:2 max:381618 sd:110015\n",
            "\t5: \"ind_forme_1km\" NUMERICAL mean:0.0183263 min:3.03815e-09 max:1 sd:0.0728845\n",
            "\t6: \"ind_forme_2km\" NUMERICAL mean:0.00629488 min:2.47632e-09 max:1 sd:0.0382642\n",
            "\t7: \"ind_forme_5km\" NUMERICAL mean:0.00177156 min:2.00777e-09 max:1 sd:0.017472\n",
            "\t10: \"p_max_1km\" NUMERICAL mean:467.042 min:39.1468 max:12148.8 sd:706.054\n",
            "\t11: \"p_max_2km\" NUMERICAL mean:636.178 min:95.2995 max:12148.8 sd:914.619\n",
            "\t12: \"p_max_5km\" NUMERICAL mean:1184.99 min:139.262 max:12148.8 sd:1734.06\n",
            "\t13: \"perimetre\" NUMERICAL mean:44.607 min:2.35528 max:12148.8 sd:42.3707\n",
            "\t14: \"plus_proche_bat\" NUMERICAL mean:6.91179 min:0 max:745.947 sd:17.6601\n",
            "\t15: \"s_max_1km\" NUMERICAL mean:8028.29 min:94.89 max:165148 sd:12523.5\n",
            "\t16: \"s_max_2km\" NUMERICAL mean:12551.3 min:239.125 max:165148 sd:16463.6\n",
            "\t17: \"s_max_5km\" NUMERICAL mean:26231.7 min:430.455 max:165148 sd:31024.8\n",
            "\t18: \"surface\" NUMERICAL mean:137.803 min:0.23 max:165148 sd:600.78\n",
            "\n",
            "CATEGORICAL: 6 (27.2727%)\n",
            "\t2: \"geometrie\" CATEGORICAL has-dict vocab-size:1 num-oods:267232 (100%)\n",
            "\t8: \"isole\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"f\" 267232 (100%)\n",
            "\t9: \"niveau\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"n0\" 267232 (100%)\n",
            "\t19: \"symbo\" CATEGORICAL has-dict vocab-size:34 num-oods:6 (0.00224524%) most-frequent:\"BATI_QQUE\" 225118 (84.2407%)\n",
            "\t20: \"territoire\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"FXX\" 267232 (100%)\n",
            "\t21: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 2022-12-07T14:05:19.79790332+00:00 kernel.cc:883] Configure learner\n",
            "[INFO 2022-12-07T14:05:19.809581978+00:00 kernel.cc:913] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"acces\"\n",
            "features: \"density_building_500m\"\n",
            "features: \"geometrie\"\n",
            "features: \"hauteur\"\n",
            "features: \"id\"\n",
            "features: \"ind_forme_1km\"\n",
            "features: \"ind_forme_2km\"\n",
            "features: \"ind_forme_5km\"\n",
            "features: \"isole\"\n",
            "features: \"niveau\"\n",
            "features: \"p_max_1km\"\n",
            "features: \"p_max_2km\"\n",
            "features: \"p_max_5km\"\n",
            "features: \"perimetre\"\n",
            "features: \"plus_proche_bat\"\n",
            "features: \"s_max_1km\"\n",
            "features: \"s_max_2km\"\n",
            "features: \"s_max_5km\"\n",
            "features: \"surface\"\n",
            "features: \"symbo\"\n",
            "features: \"territoire\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 2022-12-07T14:05:19.810235362+00:00 kernel.cc:916] Deployment config:\n",
            "cache_path: \"/tmp/tmpwjm4p8t5/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 2022-12-07T14:05:19.810263123+00:00 kernel.cc:945] Train model\n",
            "[INFO 2022-12-07T14:05:19.810608346+00:00 random_forest.cc:407] Training random forest on 267232 example(s) and 21 feature(s).\n",
            "[INFO 2022-12-07T14:05:20.633860816+00:00 random_forest.cc:796] Training of tree  1/300 (tree index:1) done accuracy:0.999645 logloss:0.012795\n",
            "[INFO 2022-12-07T14:05:24.077670152+00:00 random_forest.cc:796] Training of tree  11/300 (tree index:10) done accuracy:0.999834 logloss:0.00121708\n",
            "[INFO 2022-12-07T14:05:27.498700412+00:00 random_forest.cc:796] Training of tree  21/300 (tree index:20) done accuracy:0.99991 logloss:0.00108717\n",
            "[INFO 2022-12-07T14:05:31.44144225+00:00 random_forest.cc:796] Training of tree  31/300 (tree index:30) done accuracy:0.999925 logloss:0.000803621\n",
            "[INFO 2022-12-07T14:05:34.869952048+00:00 random_forest.cc:796] Training of tree  41/300 (tree index:41) done accuracy:0.999921 logloss:0.000650485\n",
            "[INFO 2022-12-07T14:05:38.297745274+00:00 random_forest.cc:796] Training of tree  51/300 (tree index:50) done accuracy:0.999914 logloss:0.000629574\n",
            "[INFO 2022-12-07T14:05:41.377684887+00:00 random_forest.cc:796] Training of tree  61/300 (tree index:60) done accuracy:0.999914 logloss:0.000483868\n",
            "[INFO 2022-12-07T14:05:45.807808506+00:00 random_forest.cc:796] Training of tree  71/300 (tree index:70) done accuracy:0.999921 logloss:0.000476817\n",
            "[INFO 2022-12-07T14:05:50.064359315+00:00 random_forest.cc:796] Training of tree  81/300 (tree index:80) done accuracy:0.999925 logloss:0.00047141\n",
            "[INFO 2022-12-07T14:05:53.56781063+00:00 random_forest.cc:796] Training of tree  91/300 (tree index:89) done accuracy:0.999921 logloss:0.000471307\n",
            "[INFO 2022-12-07T14:05:59.962494534+00:00 random_forest.cc:796] Training of tree  101/300 (tree index:101) done accuracy:0.999929 logloss:0.000456077\n",
            "[INFO 2022-12-07T14:06:05.981074121+00:00 random_forest.cc:796] Training of tree  111/300 (tree index:110) done accuracy:0.999933 logloss:0.000462339\n",
            "[INFO 2022-12-07T14:06:10.960527153+00:00 random_forest.cc:796] Training of tree  121/300 (tree index:120) done accuracy:0.999929 logloss:0.000457961\n",
            "[INFO 2022-12-07T14:06:14.373457117+00:00 random_forest.cc:796] Training of tree  131/300 (tree index:130) done accuracy:0.999933 logloss:0.000448131\n",
            "[INFO 2022-12-07T14:06:17.600322186+00:00 random_forest.cc:796] Training of tree  141/300 (tree index:140) done accuracy:0.999933 logloss:0.000444241\n",
            "[INFO 2022-12-07T14:06:20.780660426+00:00 random_forest.cc:796] Training of tree  151/300 (tree index:149) done accuracy:0.999933 logloss:0.000445954\n",
            "[INFO 2022-12-07T14:06:27.831117761+00:00 random_forest.cc:796] Training of tree  161/300 (tree index:160) done accuracy:0.999929 logloss:0.000444211\n",
            "[INFO 2022-12-07T14:06:35.764994042+00:00 random_forest.cc:796] Training of tree  171/300 (tree index:170) done accuracy:0.999936 logloss:0.000446081\n",
            "[INFO 2022-12-07T14:06:40.81937527+00:00 random_forest.cc:796] Training of tree  181/300 (tree index:180) done accuracy:0.999933 logloss:0.000446544\n",
            "[INFO 2022-12-07T14:06:44.411476645+00:00 random_forest.cc:796] Training of tree  191/300 (tree index:190) done accuracy:0.999933 logloss:0.00044636\n",
            "[INFO 2022-12-07T14:06:47.97995658+00:00 random_forest.cc:796] Training of tree  201/300 (tree index:200) done accuracy:0.999933 logloss:0.000446916\n",
            "[INFO 2022-12-07T14:06:51.052972317+00:00 random_forest.cc:796] Training of tree  211/300 (tree index:210) done accuracy:0.999933 logloss:0.00044579\n",
            "[INFO 2022-12-07T14:06:54.342099551+00:00 random_forest.cc:796] Training of tree  221/300 (tree index:220) done accuracy:0.999929 logloss:0.000438688\n",
            "[INFO 2022-12-07T14:06:57.837832246+00:00 random_forest.cc:796] Training of tree  231/300 (tree index:230) done accuracy:0.999925 logloss:0.000437064\n",
            "[INFO 2022-12-07T14:07:00.737615125+00:00 random_forest.cc:796] Training of tree  241/300 (tree index:240) done accuracy:0.999925 logloss:0.000430732\n",
            "[INFO 2022-12-07T14:07:04.043476539+00:00 random_forest.cc:796] Training of tree  251/300 (tree index:250) done accuracy:0.999925 logloss:0.00043105\n",
            "[INFO 2022-12-07T14:07:07.644951255+00:00 random_forest.cc:796] Training of tree  261/300 (tree index:259) done accuracy:0.999925 logloss:0.000431982\n",
            "[INFO 2022-12-07T14:07:10.970858278+00:00 random_forest.cc:796] Training of tree  271/300 (tree index:270) done accuracy:0.999925 logloss:0.000431537\n",
            "[INFO 2022-12-07T14:07:13.960996691+00:00 random_forest.cc:796] Training of tree  281/300 (tree index:280) done accuracy:0.999925 logloss:0.000432792\n",
            "[INFO 2022-12-07T14:07:16.910946768+00:00 random_forest.cc:796] Training of tree  291/300 (tree index:290) done accuracy:0.999929 logloss:0.000429723\n",
            "[INFO 2022-12-07T14:07:19.798274841+00:00 random_forest.cc:796] Training of tree  300/300 (tree index:299) done accuracy:0.999929 logloss:0.000425221\n",
            "[INFO 2022-12-07T14:07:19.798990233+00:00 random_forest.cc:876] Final OOB metrics: accuracy:0.999929 logloss:0.000425221\n",
            "[INFO 2022-12-07T14:07:19.825075126+00:00 kernel.cc:962] Export model in log directory: /tmp/tmpwjm4p8t5 with prefix 33f3e160e11e4e25\n",
            "[INFO 2022-12-07T14:07:19.873862603+00:00 kernel.cc:979] Save model in resources\n",
            "[INFO 2022-12-07T14:07:19.881412298+00:00 abstract_model.cc:844] Model self evaluation:\n",
            "Number of predictions (without weights): 267232\n",
            "Number of predictions (with weights): 267232\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.999929  CI95[W][0.999896 0.999953]\n",
            "LogLoss: : 0.000425221\n",
            "ErrorRate: : 7.11083e-05\n",
            "\n",
            "Default Accuracy: : 0.990125\n",
            "Default LogLoss: : 0.0554278\n",
            "Default ErrorRate: : 0.0098753\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "   0       1     2\n",
            "0  0       0     0\n",
            "1  0  264587     6\n",
            "2  0      13  2626\n",
            "Total: 267232\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 2022-12-07T14:07:19.919605391+00:00 kernel.cc:1175] Loading model from path /tmp/tmpwjm4p8t5/model/ with prefix 33f3e160e11e4e25\n",
            "[INFO 2022-12-07T14:07:20.012355646+00:00 decision_forest.cc:640] Model loaded with 300 root(s), 34364 node(s), and 17 input feature(s).\n",
            "[INFO 2022-12-07T14:07:20.012410578+00:00 abstract_model.cc:1306] Engine \"RandomForestGeneric\" built\n",
            "[INFO 2022-12-07T14:07:20.012456701+00:00 kernel.cc:1021] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:02:02.353532\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f15bcff5550> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f15bcff5550> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15b51ad3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Specify the model.\n",
        "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.\n",
        "model_1.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBnjxdip-MC0"
      },
      "source": [
        "### Remarks\n",
        "\n",
        "-   No input features are specified. Therefore, all the columns will be used as\n",
        "    input features except for the label. The feature used by the model are shown\n",
        "    in the training logs and in the `model.summary()`.\n",
        "-   DFs consume natively numerical, categorical, categorical-set features and\n",
        "    missing-values. Numerical features do not need to be normalized. Categorical\n",
        "    string values do not need to be encoded in a dictionary.\n",
        "-   No training hyper-parameters are specified. Therefore the default\n",
        "    hyper-parameters will be used. Default hyper-parameters provide\n",
        "    reasonable results in most situations.\n",
        "-   Calling `compile` on the model before the `fit` is optional. Compile can be\n",
        "    used to provide extra evaluation metrics.\n",
        "-   Training algorithms do not need validation datasets. If a validation dataset\n",
        "    is provided, it will only be used to show metrics.\n",
        "-   Tweak the `verbose` argument to `RandomForestModel` to control the amount of\n",
        "    displayed training logs. Set `verbose=0` to hide most of the logs. Set\n",
        "    `verbose=2` to show all the logs.\n",
        "\n",
        "**Note:** A *Categorical-Set* feature is composed of a set of categorical values (while a *Categorical* is only one value). More details and examples are given later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSdtNJUArBpl"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udtu_uS1paSu"
      },
      "source": [
        "Let's evaluate our model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xUy4ULEMtDXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b63276-2df9-4294-db18-eaaf9458e4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 4s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model_1.compile(metrics=[\"accuracy\"])\n",
        "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlhfzZ34pfO4"
      },
      "source": [
        "**Remark:** The test accuracy is close to the Out-of-bag accuracy\n",
        "shown in the training logs.\n",
        "\n",
        "See the **Model Self Evaluation** section below for more evaluation methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBFtUeElRYz"
      },
      "source": [
        "## Prepare this model for TensorFlow Serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbC4lmgfr5Sm"
      },
      "source": [
        "Export the model to the SavedModel format for later re-use e.g.\n",
        "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "08YWGr9U2fza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f596b7-f5fe-4407-f7cc-b3c7e43516bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model_1.save(\"/content/drive/MyDrive/pire/mysavemodel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-8R02_SXpbq"
      },
      "source": [
        "## Plot the model\n",
        "\n",
        "Plotting a decision tree and following the first branches helps learning about decision forests. In some cases, plotting a model can even be used for debugging.\n",
        "\n",
        "Because of the difference in the way they are trained, some models are more interesting to plan than others. Because of the noise injected during training and the depth of the trees, plotting Random Forest is less informative than plotting a CART or the first tree of a Gradient Boosted Tree.\n",
        "\n",
        "Never the less, let's plot the first tree of our Random Forest model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KUIxf8N6Yjl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "812c8443-9149-46df-bb4f-6befa8fb5f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_1cea1540b5734867bc813312a768ffc5\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9899824871272901, 0.010017512872709855], \"num_examples\": 267232.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 139.062255859375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8375084631008801, 0.16249153689911983], \"num_examples\": 4431.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 3571.22021484375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9275717284814555, 0.07242827151854443], \"num_examples\": 2858.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.7978013753890991}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 157.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9814883376527213, 0.018511662347278787], \"num_examples\": 2701.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"symbo\", \"mask\": [\"EGLISE_SURF\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 22.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9895483389324374, 0.010451661067562523], \"num_examples\": 2679.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"symbo\", \"mask\": [\"BATI_QQUE\", \"HANGAR\", \"BATI_COMMERCIAL\", \"BATI_PUBLIC\", \"SERRE_SURF\", \"HANGAR_PUBLIC\", \"SILO_SURF\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9828134945894335, 0.01718650541056652], \"num_examples\": 1571.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 2409.1826171875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9361702127659575, 0.06382978723404255], \"num_examples\": 141.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 18.56999969482422}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 9.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 132.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9874125874125874, 0.012587412587412588], \"num_examples\": 1430.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 98.1874771118164}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 7.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9922698524244554, 0.007730147575544624], \"num_examples\": 1423.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_5km\", \"threshold\": 0.00022127930424176157}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9955621301775148, 0.004437869822485207], \"num_examples\": 1352.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 195.63963317871094}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9865470852017937, 0.013452914798206279], \"num_examples\": 446.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 19.700000762939453}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5, 0.5], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9931818181818182, 0.006818181818181818], \"num_examples\": 440.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 20393.21875}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 906.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9295774647887324, 0.07042253521126761], \"num_examples\": 71.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"density_building_500m\", \"threshold\": 1056.788818359375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 36.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8571428571428571, 0.14285714285714285], \"num_examples\": 35.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 145.7540283203125}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9666666666666667, 0.03333333333333333], \"num_examples\": 30.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 12.350000381469727}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2, 0.8], \"num_examples\": 5.0}}]}]}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9990974729241877, 0.0009025270758122744], \"num_examples\": 1108.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 71.62785339355469}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8, 0.2], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 1103.0}}]}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.673871582962492, 0.32612841703750794], \"num_examples\": 1573.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 206.72650146484375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3411458333333333, 0.6588541666666666], \"num_examples\": 384.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.7991673946380615}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 243.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9290780141843972, 0.07092198581560284], \"num_examples\": 141.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"p_max_2km\", \"threshold\": 238.07362365722656}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9558823529411765, 0.04411764705882353], \"num_examples\": 136.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 2678.2626953125}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8867924528301887, 0.11320754716981132], \"num_examples\": 53.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 2755.34765625}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9782608695652174, 0.021739130434782608], \"num_examples\": 46.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 3.8000001907348633}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 37.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8888888888888888, 0.1111111111111111], \"num_examples\": 9.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2857142857142857, 0.7142857142857143], \"num_examples\": 7.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 83.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2, 0.8], \"num_examples\": 5.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7813288477712363, 0.21867115222876365], \"num_examples\": 1189.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"p_max_1km\", \"threshold\": 207.4722900390625}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9683908045977011, 0.031609195402298854], \"num_examples\": 696.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.7978014945983887}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.975397973950796, 0.024602026049204053], \"num_examples\": 691.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 1141.06494140625}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9477351916376306, 0.05226480836236934], \"num_examples\": 287.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 98.19889831542969}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 15.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 272.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.995049504950495, 0.0049504950495049506], \"num_examples\": 404.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 170.4121551513672}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9795918367346939, 0.02040816326530612], \"num_examples\": 98.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"perimetre\", \"threshold\": 171.06471252441406}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 90.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.75, 0.25], \"num_examples\": 8.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 306.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5172413793103449, 0.4827586206896552], \"num_examples\": 493.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 1084.8349609375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.19166666666666668, 0.8083333333333333], \"num_examples\": 240.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.7996969819068909}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 192.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9583333333333334, 0.041666666666666664], \"num_examples\": 48.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 1315.030029296875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 43.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6, 0.4], \"num_examples\": 5.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8260869565217391, 0.17391304347826086], \"num_examples\": 253.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"density_building_500m\", \"threshold\": 26.73802947998047}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8436213991769548, 0.15637860082304528], \"num_examples\": 243.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 1057.544921875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9883720930232558, 0.011627906976744186], \"num_examples\": 172.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 62.356048583984375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8571428571428571, 0.14285714285714285], \"num_examples\": 7.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9939393939393939, 0.006060606060606061], \"num_examples\": 165.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"s_max_1km\", \"threshold\": 1107.7451171875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 154.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9090909090909091, 0.09090909090909091], \"num_examples\": 11.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"p_max_1km\", \"threshold\": 170.0165252685547}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8, 0.2], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 6.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.49295774647887325, 0.5070422535211268], \"num_examples\": 71.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.7826314568519592}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 36.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 35.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 10.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 913.3125}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8, 0.2], \"num_examples\": 5.0}}]}]}]}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9925533007865267, 0.007446699213473312], \"num_examples\": 262801.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 100.11898803710938}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 1516.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9983121878408634, 0.001687812159136575], \"num_examples\": 261285.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"symbo\", \"mask\": [\"<OOD>\", \"EGLISE_SURF\", \"SILO_SURF\", \"CHATEAU_EAU_SURF\", \"TOUR_MOULIN_SURF\", \"BATI_INDUSTRIEL\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.24581005586592178, 0.7541899441340782], \"num_examples\": 358.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"symbo\", \"mask\": [\"EGLISE_SURF\", \"CHATEAU_EAU_SURF\", \"TOUR_MOULIN_SURF\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 231.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6929133858267716, 0.30708661417322836], \"num_examples\": 127.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 20.149999618530273}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 34.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.946236559139785, 0.053763440860215055], \"num_examples\": 93.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"id\", \"threshold\": 157965.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7272727272727273, 0.2727272727272727], \"num_examples\": 11.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 234.0625}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 5.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.975609756097561, 0.024390243902439025], \"num_examples\": 82.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"surface\", \"threshold\": 187.03500366210938}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6, 0.4], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 77.0}}]}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9993446442874827, 0.0006553557125172941], \"num_examples\": 260927.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ind_forme_1km\", \"threshold\": 0.798894464969635}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 105.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.999746953861254, 0.0002530461387459647], \"num_examples\": 260822.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"hauteur\", \"threshold\": 20.029998779296875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.03125, 0.96875], \"num_examples\": 64.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"acces\", \"threshold\": 2.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 59.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9999846601063055, 1.5339893694536696e-05], \"num_examples\": 260758.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"density_building_500m\", \"threshold\": 2088.74951171875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9992391097584173, 0.0007608902415826517], \"num_examples\": 5257.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"plus_proche_bat\", \"threshold\": 17.6918888092041}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2, 0.8], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 5252.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 255501.0}}]}]}]}]}]}]}, \"#tree_plot_1cea1540b5734867bc813312a768ffc5\")\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPcL_hDnY7Zy"
      },
      "source": [
        "The root node on the left contains the first condition (`bill_depth_mm >= 16.55`), number of examples (240) and label distribution (the red-blue-green bar).\n",
        "\n",
        "Examples that evaluates true to `bill_depth_mm >= 16.55` are branched to the green path. The other ones are branched to the red path.\n",
        "\n",
        "The deeper the node, the more `pure` they become i.e. the label distribution is biased toward a subset of classes. \n",
        "\n",
        "**Note:** Over the mouse on top of the plot for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ob3ovQ2seVY"
      },
      "source": [
        "## Model structure and feature importance\n",
        "\n",
        "The overall structure of the model is show with `.summary()`. You will see:\n",
        "\n",
        "-   **Type**: The learning algorithm used to train the model (`Random Forest` in\n",
        "    our case).\n",
        "-   **Task**: The problem solved by the model (`Classification` in our case).\n",
        "-   **Input Features**: The input features of the model.\n",
        "-   **Variable Importance**: Different measures of the importance of each\n",
        "    feature for the model.\n",
        "-   **Out-of-bag evaluation**: The out-of-bag evaluation of the model. This is a\n",
        "    cheap and efficient alternative to cross-validation.\n",
        "-   **Number of {trees, nodes} and other metrics**: Statistics about the\n",
        "    structure of the decisions forests.\n",
        "\n",
        "**Remark:** The summary's content depends on the learning algorithm (e.g.\n",
        "Out-of-bag is only available for Random Forest) and the hyper-parameters (e.g.\n",
        "the *mean-decrease-in-accuracy* variable importance can be disabled in the\n",
        "hyper-parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kzXME28Lq7Il",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9f87f78e-95ab-45a0-a48b-736646abcc98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (21):\n",
            "\tacces\n",
            "\tdensity_building_500m\n",
            "\tgeometrie\n",
            "\thauteur\n",
            "\tid\n",
            "\tind_forme_1km\n",
            "\tind_forme_2km\n",
            "\tind_forme_5km\n",
            "\tisole\n",
            "\tniveau\n",
            "\tp_max_1km\n",
            "\tp_max_2km\n",
            "\tp_max_5km\n",
            "\tperimetre\n",
            "\tplus_proche_bat\n",
            "\ts_max_1km\n",
            "\ts_max_2km\n",
            "\ts_max_5km\n",
            "\tsurface\n",
            "\tsymbo\n",
            "\tterritoire\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.             \"geometrie\"  8.038726 ################\n",
            "    2.                 \"isole\"  8.038726 ################\n",
            "    3.                \"niveau\"  8.038726 ################\n",
            "    4.            \"territoire\"  8.038726 ################\n",
            "    5.               \"__LABEL\"  8.038726 ################\n",
            "    6.             \"p_max_5km\"  7.822637 ###############\n",
            "    7.             \"s_max_5km\"  7.807476 ###############\n",
            "    8.                 \"acces\"  7.723480 ###############\n",
            "    9.             \"p_max_2km\"  7.658691 ##############\n",
            "   10.             \"s_max_2km\"  7.581745 ##############\n",
            "   11.         \"ind_forme_5km\"  6.943520 ############\n",
            "   12.             \"p_max_1km\"  6.868153 ############\n",
            "   13.             \"s_max_1km\"  6.824251 ############\n",
            "   14.                    \"id\"  6.674040 ###########\n",
            "   15.         \"ind_forme_2km\"  6.388420 ###########\n",
            "   16. \"density_building_500m\"  5.758680 #########\n",
            "   17.             \"perimetre\"  5.339094 ########\n",
            "   18.               \"hauteur\"  5.227398 #######\n",
            "   19.               \"surface\"  4.590324 #####\n",
            "   20.                 \"symbo\"  3.772831 ###\n",
            "   21.         \"ind_forme_1km\"  3.153265 #\n",
            "   22.       \"plus_proche_bat\"  2.612119 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.       \"plus_proche_bat\" 107.000000 ################\n",
            "    2.         \"ind_forme_1km\" 71.000000 ##########\n",
            "    3.               \"surface\" 43.000000 ######\n",
            "    4.             \"perimetre\" 25.000000 ###\n",
            "    5.                 \"symbo\" 23.000000 ###\n",
            "    6.         \"ind_forme_2km\" 15.000000 #\n",
            "    7.         \"ind_forme_5km\" 12.000000 #\n",
            "    8. \"density_building_500m\"  2.000000 \n",
            "    9.               \"hauteur\"  2.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.       \"plus_proche_bat\" 2130.000000 ################\n",
            "    2.               \"hauteur\" 2054.000000 ###############\n",
            "    3.                 \"symbo\" 1809.000000 #############\n",
            "    4.         \"ind_forme_1km\" 1668.000000 ############\n",
            "    5. \"density_building_500m\" 1552.000000 ###########\n",
            "    6.                    \"id\" 1125.000000 #######\n",
            "    7.               \"surface\" 1092.000000 #######\n",
            "    8.             \"perimetre\" 1063.000000 #######\n",
            "    9.             \"p_max_1km\" 790.000000 ####\n",
            "   10.             \"s_max_1km\" 774.000000 ####\n",
            "   11.         \"ind_forme_2km\" 752.000000 ####\n",
            "   12.         \"ind_forme_5km\" 628.000000 ###\n",
            "   13.             \"s_max_2km\" 405.000000 #\n",
            "   14.             \"p_max_2km\" 392.000000 #\n",
            "   15.             \"p_max_5km\" 314.000000 #\n",
            "   16.             \"s_max_5km\" 293.000000 \n",
            "   17.                 \"acces\" 191.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.       \"plus_proche_bat\" 2404792.397552 ################\n",
            "    2.         \"ind_forme_1km\" 781069.220092 #####\n",
            "    3.                 \"symbo\" 481324.655956 ###\n",
            "    4.               \"surface\" 184507.339690 #\n",
            "    5.               \"hauteur\" 158836.728796 #\n",
            "    6.             \"perimetre\" 124237.907109 \n",
            "    7. \"density_building_500m\" 83696.915082 \n",
            "    8.         \"ind_forme_2km\" 75885.338298 \n",
            "    9.         \"ind_forme_5km\" 36439.793139 \n",
            "   10.             \"s_max_1km\" 27315.770188 \n",
            "   11.                    \"id\" 26869.327067 \n",
            "   12.             \"p_max_1km\" 23765.570373 \n",
            "   13.             \"s_max_2km\" 3864.743726 \n",
            "   14.             \"p_max_2km\" 3075.475775 \n",
            "   15.                 \"acces\" 2368.031721 \n",
            "   16.             \"s_max_5km\" 2325.228940 \n",
            "   17.             \"p_max_5km\" 1786.775711 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.999929 logloss:0.000425221\n",
            "Number of trees: 300\n",
            "Total number of nodes: 34364\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 114.547 StdDev: 53.3525\n",
            "Min: 19 Max: 295 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  19,  32)  8   2.67%   2.67% ##\n",
            "[  32,  46) 15   5.00%   7.67% ####\n",
            "[  46,  60) 18   6.00%  13.67% #####\n",
            "[  60,  74) 32  10.67%  24.33% #########\n",
            "[  74,  88) 26   8.67%  33.00% #######\n",
            "[  88, 102) 36  12.00%  45.00% ##########\n",
            "[ 102, 115) 26   8.67%  53.67% #######\n",
            "[ 115, 129) 31  10.33%  64.00% #########\n",
            "[ 129, 143) 35  11.67%  75.67% ##########\n",
            "[ 143, 157) 16   5.33%  81.00% ####\n",
            "[ 157, 171) 15   5.00%  86.00% ####\n",
            "[ 171, 185) 12   4.00%  90.00% ###\n",
            "[ 185, 199)  7   2.33%  92.33% ##\n",
            "[ 199, 212)  4   1.33%  93.67% #\n",
            "[ 212, 226)  7   2.33%  96.00% ##\n",
            "[ 226, 240)  3   1.00%  97.00% #\n",
            "[ 240, 254)  2   0.67%  97.67% #\n",
            "[ 254, 268)  3   1.00%  98.67% #\n",
            "[ 268, 282)  3   1.00%  99.67% #\n",
            "[ 282, 295]  1   0.33% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 17332 Average: 8.42944 StdDev: 2.67007\n",
            "Min: 1 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  1,  2)  173   1.00%   1.00% #\n",
            "[  2,  3)  211   1.22%   2.22% #\n",
            "[  3,  4)  278   1.60%   3.82% #\n",
            "[  4,  5)  537   3.10%   6.92% ##\n",
            "[  5,  6)  950   5.48%  12.40% ###\n",
            "[  6,  7) 1626   9.38%  21.78% ######\n",
            "[  7,  8) 2326  13.42%  35.20% ########\n",
            "[  8,  9) 2771  15.99%  51.19% ##########\n",
            "[  9, 10) 2563  14.79%  65.98% #########\n",
            "[ 10, 11) 2311  13.33%  79.31% ########\n",
            "[ 11, 12) 1587   9.16%  88.47% ######\n",
            "[ 12, 13)  901   5.20%  93.66% ###\n",
            "[ 13, 14)  504   2.91%  96.57% ##\n",
            "[ 14, 15)  342   1.97%  98.55% #\n",
            "[ 15, 15]  252   1.45% 100.00% #\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 17332 Average: 4625.53 StdDev: 25124.4\n",
            "Min: 5 Max: 261841 Ignored: 0\n",
            "----------------------------------------------\n",
            "[      5,  13096) 16498  95.19%  95.19% ##########\n",
            "[  13096,  26188)   218   1.26%  96.45%\n",
            "[  26188,  39280)   125   0.72%  97.17%\n",
            "[  39280,  52372)    68   0.39%  97.56%\n",
            "[  52372,  65464)    53   0.31%  97.87%\n",
            "[  65464,  78556)    38   0.22%  98.08%\n",
            "[  78556,  91647)    44   0.25%  98.34%\n",
            "[  91647, 104739)    35   0.20%  98.54%\n",
            "[ 104739, 117831)    26   0.15%  98.69%\n",
            "[ 117831, 130923)    31   0.18%  98.87%\n",
            "[ 130923, 144015)    21   0.12%  98.99%\n",
            "[ 144015, 157107)    17   0.10%  99.09%\n",
            "[ 157107, 170199)    15   0.09%  99.17%\n",
            "[ 170199, 183290)     6   0.03%  99.21%\n",
            "[ 183290, 196382)     3   0.02%  99.23%\n",
            "[ 196382, 209474)    10   0.06%  99.28%\n",
            "[ 209474, 222566)    15   0.09%  99.37%\n",
            "[ 222566, 235658)    33   0.19%  99.56%\n",
            "[ 235658, 248750)    40   0.23%  99.79%\n",
            "[ 248750, 261841]    36   0.21% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t2130 : plus_proche_bat [NUMERICAL]\n",
            "\t2054 : hauteur [NUMERICAL]\n",
            "\t1809 : symbo [CATEGORICAL]\n",
            "\t1668 : ind_forme_1km [NUMERICAL]\n",
            "\t1552 : density_building_500m [NUMERICAL]\n",
            "\t1125 : id [NUMERICAL]\n",
            "\t1092 : surface [NUMERICAL]\n",
            "\t1063 : perimetre [NUMERICAL]\n",
            "\t790 : p_max_1km [NUMERICAL]\n",
            "\t774 : s_max_1km [NUMERICAL]\n",
            "\t752 : ind_forme_2km [NUMERICAL]\n",
            "\t628 : ind_forme_5km [NUMERICAL]\n",
            "\t405 : s_max_2km [NUMERICAL]\n",
            "\t392 : p_max_2km [NUMERICAL]\n",
            "\t314 : p_max_5km [NUMERICAL]\n",
            "\t293 : s_max_5km [NUMERICAL]\n",
            "\t191 : acces [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t107 : plus_proche_bat [NUMERICAL]\n",
            "\t71 : ind_forme_1km [NUMERICAL]\n",
            "\t43 : surface [NUMERICAL]\n",
            "\t25 : perimetre [NUMERICAL]\n",
            "\t23 : symbo [CATEGORICAL]\n",
            "\t15 : ind_forme_2km [NUMERICAL]\n",
            "\t12 : ind_forme_5km [NUMERICAL]\n",
            "\t2 : hauteur [NUMERICAL]\n",
            "\t2 : density_building_500m [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t175 : plus_proche_bat [NUMERICAL]\n",
            "\t175 : ind_forme_1km [NUMERICAL]\n",
            "\t90 : symbo [CATEGORICAL]\n",
            "\t81 : surface [NUMERICAL]\n",
            "\t54 : perimetre [NUMERICAL]\n",
            "\t49 : ind_forme_2km [NUMERICAL]\n",
            "\t34 : density_building_500m [NUMERICAL]\n",
            "\t21 : ind_forme_5km [NUMERICAL]\n",
            "\t17 : hauteur [NUMERICAL]\n",
            "\t13 : s_max_1km [NUMERICAL]\n",
            "\t12 : p_max_1km [NUMERICAL]\n",
            "\t3 : s_max_2km [NUMERICAL]\n",
            "\t1 : s_max_5km [NUMERICAL]\n",
            "\t1 : p_max_2km [NUMERICAL]\n",
            "\t1 : id [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t279 : ind_forme_1km [NUMERICAL]\n",
            "\t253 : plus_proche_bat [NUMERICAL]\n",
            "\t192 : symbo [CATEGORICAL]\n",
            "\t138 : surface [NUMERICAL]\n",
            "\t91 : ind_forme_2km [NUMERICAL]\n",
            "\t86 : perimetre [NUMERICAL]\n",
            "\t76 : hauteur [NUMERICAL]\n",
            "\t76 : density_building_500m [NUMERICAL]\n",
            "\t45 : ind_forme_5km [NUMERICAL]\n",
            "\t40 : s_max_1km [NUMERICAL]\n",
            "\t39 : p_max_1km [NUMERICAL]\n",
            "\t24 : id [NUMERICAL]\n",
            "\t11 : s_max_2km [NUMERICAL]\n",
            "\t6 : p_max_2km [NUMERICAL]\n",
            "\t6 : acces [NUMERICAL]\n",
            "\t4 : s_max_5km [NUMERICAL]\n",
            "\t4 : p_max_5km [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t420 : ind_forme_1km [NUMERICAL]\n",
            "\t361 : symbo [CATEGORICAL]\n",
            "\t358 : plus_proche_bat [NUMERICAL]\n",
            "\t204 : surface [NUMERICAL]\n",
            "\t204 : hauteur [NUMERICAL]\n",
            "\t171 : density_building_500m [NUMERICAL]\n",
            "\t148 : ind_forme_2km [NUMERICAL]\n",
            "\t133 : perimetre [NUMERICAL]\n",
            "\t90 : s_max_1km [NUMERICAL]\n",
            "\t86 : p_max_1km [NUMERICAL]\n",
            "\t73 : ind_forme_5km [NUMERICAL]\n",
            "\t65 : id [NUMERICAL]\n",
            "\t20 : s_max_2km [NUMERICAL]\n",
            "\t16 : p_max_2km [NUMERICAL]\n",
            "\t12 : acces [NUMERICAL]\n",
            "\t11 : p_max_5km [NUMERICAL]\n",
            "\t6 : s_max_5km [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t875 : symbo [CATEGORICAL]\n",
            "\t793 : ind_forme_1km [NUMERICAL]\n",
            "\t660 : hauteur [NUMERICAL]\n",
            "\t645 : plus_proche_bat [NUMERICAL]\n",
            "\t484 : density_building_500m [NUMERICAL]\n",
            "\t423 : surface [NUMERICAL]\n",
            "\t350 : perimetre [NUMERICAL]\n",
            "\t296 : id [NUMERICAL]\n",
            "\t272 : ind_forme_2km [NUMERICAL]\n",
            "\t268 : p_max_1km [NUMERICAL]\n",
            "\t251 : s_max_1km [NUMERICAL]\n",
            "\t160 : ind_forme_5km [NUMERICAL]\n",
            "\t106 : s_max_2km [NUMERICAL]\n",
            "\t95 : p_max_2km [NUMERICAL]\n",
            "\t65 : p_max_5km [NUMERICAL]\n",
            "\t63 : s_max_5km [NUMERICAL]\n",
            "\t59 : acces [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t15223 : HigherCondition\n",
            "\t1364 : ContainsBitmapCondition\n",
            "\t445 : ContainsCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t277 : HigherCondition\n",
            "\t23 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t637 : HigherCondition\n",
            "\t90 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1178 : HigherCondition\n",
            "\t190 : ContainsBitmapCondition\n",
            "\t2 : ContainsCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2017 : HigherCondition\n",
            "\t344 : ContainsBitmapCondition\n",
            "\t17 : ContainsCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t4990 : HigherCondition\n",
            "\t768 : ContainsBitmapCondition\n",
            "\t107 : ContainsCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.999645 logloss:0.012795\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.999834 logloss:0.00121708\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.99991 logloss:0.00108717\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000803621\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.999921 logloss:0.000650485\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.999914 logloss:0.000629574\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.999914 logloss:0.000483868\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.999921 logloss:0.000476817\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.999925 logloss:0.00047141\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.999921 logloss:0.000471307\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000456077\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000462339\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000457961\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000448131\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000444241\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000445954\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000444211\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.999936 logloss:0.000446081\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000446544\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.999933 logloss:0.00044636\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.999933 logloss:0.000446916\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.999933 logloss:0.00044579\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000438688\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000437064\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000430732\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.999925 logloss:0.00043105\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000431982\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000431537\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.999925 logloss:0.000432792\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000429723\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.999929 logloss:0.000425221\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%set_cell_height 300\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ApRpUm02zU"
      },
      "source": [
        "The information in ``summary`` are all available programmatically using the model inspector:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3xuB3jN1Cww"
      },
      "outputs": [],
      "source": [
        "# The input features\n",
        "model_1.make_inspector().features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ2RBbU51L6s"
      },
      "outputs": [],
      "source": [
        "# The feature importances\n",
        "model_1.make_inspector().variable_importances()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvyRJVk1aEk"
      },
      "source": [
        "The content of the summary and the inspector depends on the learning algorithm (`tfdf.keras.RandomForestModel` in this case) and its hyper-parameters (e.g. `compute_oob_variable_importances=True` will trigger the computation of Out-of-bag variable importances for the Random Forest learner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFVmrHtWXYKY"
      },
      "source": [
        "## Model Self Evaluation\n",
        "\n",
        "During training TFDF models can self evaluate even if no validation dataset is provided to the `fit()` method. The exact logic depends on the model. For example, Random Forest will use Out-of-bag evaluation while Gradient Boosted Trees will use internal train-validation.\n",
        "\n",
        "**Note:** While this evaluation is  computed during training, it is NOT computed on the training dataset and can be used as a low quality evaluation.\n",
        "\n",
        "The model self evaluation is available with the inspector's `evaluation()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZPzyIMmYmsI"
      },
      "outputs": [],
      "source": [
        "model_1.make_inspector().evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSz-jE0Qss_"
      },
      "source": [
        "## Plotting the training logs\n",
        "\n",
        "The training logs show the quality of the model (e.g. accuracy evaluated on the out-of-bag or validation dataset) according to the number of trees in the model. These logs are helpful to study the balance between model size and model quality.\n",
        "\n",
        "The logs are available in multiple ways:\n",
        "\n",
        "1. Displayed in during training if `fit()` is wrapped in `with sys_pipes():` (see example above).\n",
        "1. At the end of the model summary i.e. `model.summary()` (see example above).\n",
        "1. Programmatically, using the model inspector i.e. `model.make_inspector().training_logs()`.\n",
        "1. Using [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
        "\n",
        "Let's try the options 2 and 3:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbRk7xvpTKQG"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 150\n",
        "model_1.make_inspector().training_logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WynFJCEbhuF_"
      },
      "source": [
        "Let's plot it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzPH7Gggh0g1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = model_1.make_inspector().training_logs()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Logloss (out-of-bag)\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xzugBRhwuN"
      },
      "source": [
        "This dataset is small. You can see the model converging almost immediately.\n",
        "\n",
        "Let's use TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R_m-JmvU9tu"
      },
      "outputs": [],
      "source": [
        "# This cell start TensorBoard that can be slow.\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Google internal version\n",
        "# %load_ext google3.learning.brain.tensorboard.notebook.extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6mp7K6HWwqQ"
      },
      "outputs": [],
      "source": [
        "# Clear existing results (if any)\n",
        "!rm -fr \"/tmp/tensorboard_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16NbLILYo124"
      },
      "outputs": [],
      "source": [
        "# Export the meta-data to tensorboard.\n",
        "model_1.make_inspector().export_to_tensorboard(\"/tmp/tensorboard_logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSsN6aTXW0LJ"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "# Start a tensorboard instance.\n",
        "%tensorboard --logdir \"/tmp/tensorboard_logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_tlSccjZ8kE"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/beginner_tensorboard.png\"/> -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTUr6F1t-_E"
      },
      "source": [
        "## Re-train the model with a different learning algorithm\n",
        "\n",
        "The learning algorithm is defined by the model class. For\n",
        "example, `tfdf.keras.RandomForestModel()` trains a Random Forest, while\n",
        "`tfdf.keras.GradientBoostedTreesModel()` trains a Gradient Boosted Decision\n",
        "Trees.\n",
        "\n",
        "The learning algorithms are listed by calling `tfdf.keras.get_all_models()` or in the\n",
        "[learner list](https://github.com/google/yggdrasil-decision-forests/blob/main/documentation/learners.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwEAAzUZq2m8"
      },
      "outputs": [],
      "source": [
        "tfdf.keras.get_all_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmzvuI78voD4"
      },
      "source": [
        "The description of the learning algorithms and their hyper-parameters are also available in the [API reference](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf) and builtin help:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hONToBav4DE"
      },
      "outputs": [],
      "source": [
        "# help works anywhere.\n",
        "help(tfdf.keras.RandomForestModel)\n",
        "\n",
        "# ? only works in ipython or notebooks, it usually opens on a separate panel.\n",
        "tfdf.keras.RandomForestModel?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWEYvXaiwhk"
      },
      "source": [
        "## Using a subset of features\n",
        "\n",
        "The previous example did not specify the features, so all the columns were used\n",
        "as input feature (except for the label). The following example shows how to\n",
        "specify input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgn_LnRz3M7z"
      },
      "outputs": [],
      "source": [
        "feature_1 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"island\")\n",
        "\n",
        "all_features = [feature_1, feature_2]\n",
        "\n",
        "# Note: This model is only trained with two features. It will not be as good as\n",
        "# the one trained on all features.\n",
        "\n",
        "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    features=all_features, exclude_non_specified_features=True)\n",
        "\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "model_2.fit(x=train_ds, validation_data=test_ds)\n",
        "\n",
        "print(model_2.evaluate(test_ds, return_dict=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvM84cgCmbUR"
      },
      "source": [
        "**Note:** As expected, the accuracy is lower than previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFmqpivc7x7p"
      },
      "source": [
        "**TF-DF** attaches a **semantics** to each feature. This semantics controls how\n",
        "the feature is used by the model. The following semantics are currently supported:\n",
        "\n",
        "-   **Numerical**: Generally for quantities or counts with full ordering. For\n",
        "    example, the age of a person, or the number of items in a bag. Can be a\n",
        "    float or an integer. Missing values are represented with float(Nan) or with\n",
        "    an empty sparse tensor.\n",
        "-   **Categorical**: Generally for a type/class in finite set of possible values\n",
        "    without ordering. For example, the color RED in the set {RED, BLUE, GREEN}.\n",
        "    Can be a string or an integer. Missing values are represented as \"\" (empty\n",
        "    sting), value -2 or with an empty sparse tensor.\n",
        "-   **Categorical-Set**: A set of categorical values. Great to represent\n",
        "    tokenized text. Can be a string or an integer in a sparse tensor or a\n",
        "    ragged tensor (recommended). The order/index of each item doesn't matter.\n",
        "\n",
        "If not specified, the semantics is inferred from the representation type and shown in the training logs:\n",
        "\n",
        "- int, float (dense or sparse) → Numerical semantics.\n",
        "- str (dense or sparse) → Categorical semantics\n",
        "- int, str (ragged) → Categorical-Set semantics\n",
        "\n",
        "In some cases, the inferred semantics is incorrect. For example: An Enum stored as an integer is semantically categorical, but it will be detected as numerical. In this case, you should specify the semantic argument in the input. The `education_num` field of the Adult dataset is classical example.\n",
        "\n",
        "This dataset doesn't contain such a feature. However, for the demonstration, we will make the model treat the `year` as a categorical feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNRIwLYC8zrp"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "feature_1 = tfdf.keras.FeatureUsage(name=\"year\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
        "feature_3 = tfdf.keras.FeatureUsage(name=\"sex\")\n",
        "all_features = [feature_1, feature_2, feature_3]\n",
        "\n",
        "model_3 = tfdf.keras.GradientBoostedTreesModel(features=all_features, exclude_non_specified_features=True)\n",
        "model_3.compile( metrics=[\"accuracy\"])\n",
        "\n",
        "model_3.fit(x=train_ds, validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AQaNwihcpP7"
      },
      "source": [
        "Note that `year` is in the list of CATEGORICAL features (unlike the first run)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYrw7nKN40Vm"
      },
      "source": [
        "## Hyper-parameters\n",
        "\n",
        "**Hyper-parameters** are parameters of the training algorithm that impact\n",
        "the quality of the final model. They are specified in the model class\n",
        "constructor. The list of hyper-parameters is visible with the *question mark* colab command (e.g. `?tfdf.keras.GradientBoostedTreesModel`).\n",
        "\n",
        "Alternatively, you can find them on the [TensorFlow Decision Forest Github](https://github.com/tensorflow/decision-forests/blob/main/tensorflow_decision_forests/keras/wrappers_pre_generated.py) or the [Yggdrasil Decision Forest documentation](https://github.com/google/yggdrasil-decision-forests/blob/main/documentation/learners.md).\n",
        "\n",
        "The default hyper-parameters of each algorithm matches approximatively the initial publication paper. To ensure consistancy, new features and their matching hyper-parameters are always disable by default. That's why it is a good idea to tune your hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHgPr4Pt43hv"
      },
      "outputs": [],
      "source": [
        "# A classical but slighly more complex model.\n",
        "model_6 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=8)\n",
        "model_6.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uECgPGDc2P4p"
      },
      "outputs": [],
      "source": [
        "# A more complex, but possibly, more accurate model.\n",
        "model_7 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=8,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    )\n",
        "model_7.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk7wEmUZu3V0"
      },
      "source": [
        "As new training methods are published and implemented, combination of hyper-parameters can emerge as good or almost-always-better than the default parameters. To avoid changing the default hyper-parameter values these good combination are indexed and available as hyper-parameter templates.\n",
        "\n",
        "For example, the `benchmark_rank1` template is the best combination on our internal benchmarks. Those templates are versioned to allow training configuration stability e.g. `benchmark_rank1@v1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtrRhMhj3hSu"
      },
      "outputs": [],
      "source": [
        "# A good template of hyper-parameters.\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
        "model_8.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDXcKXB3u6M"
      },
      "source": [
        "The available templates are available with `predefined_hyperparameters`. Note that different learning algorithms have different templates, even if the name is similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQrWI2iv37Bo"
      },
      "outputs": [],
      "source": [
        "# The hyper-parameter templates of the Gradient Boosted Tree model.\n",
        "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcX4tov1_lwp"
      },
      "source": [
        "## Feature Preprocessing\n",
        "\n",
        "Pre-processing features is sometimes necessary to consume signals with complex\n",
        "structures, to regularize the model or to apply transfer learning.\n",
        "Pre-processing can be done in one of three ways:\n",
        "\n",
        "1.  Preprocessing on the Pandas dataframe. This solution is easy to implement\n",
        "    and generally suitable for experimentation. However, the\n",
        "    pre-processing logic will not be exported in the model by `model.save()`.\n",
        "\n",
        "2.  [Keras Preprocessing](https://keras.io/guides/preprocessing_layers/): While\n",
        "    more complex than the previous solution, Keras Preprocessing is packaged in\n",
        "    the model.\n",
        "\n",
        "3.  [TensorFlow Feature Columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns):\n",
        "    This API is part of the TF Estimator library (!= Keras) and planned for\n",
        "    deprecation. This solution is interesting when using existing preprocessing\n",
        "    code.\n",
        "\n",
        "Note: Using [TensorFlow Hub](https://www.tensorflow.org/hub)\n",
        "pre-trained embedding is often, a great way to consume text and image with\n",
        "TF-DF. For example, `hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")`. See the [Intermediate tutorial](intermediate_colab.ipynb) for more details.\n",
        "\n",
        "In the next example, pre-process the `body_mass_g` feature into `body_mass_kg = body_mass_g / 1000`. The `bill_length_mm` is consumed without pre-processing. Note that such\n",
        "monotonic transformations have generally no impact on decision forest models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGcIvTeKAApp"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "body_mass_g = tf.keras.layers.Input(shape=(1,), name=\"body_mass_g\")\n",
        "body_mass_kg = body_mass_g / 1000.0\n",
        "\n",
        "bill_length_mm = tf.keras.layers.Input(shape=(1,), name=\"bill_length_mm\")\n",
        "\n",
        "raw_inputs = {\"body_mass_g\": body_mass_g, \"bill_length_mm\": bill_length_mm}\n",
        "processed_inputs = {\"body_mass_kg\": body_mass_kg, \"bill_length_mm\": bill_length_mm}\n",
        "\n",
        "# \"preprocessor\" contains the preprocessing logic.\n",
        "preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
        "\n",
        "# \"model_4\" contains both the pre-processing logic and the decision forest.\n",
        "model_4 = tfdf.keras.RandomForestModel(preprocessing=preprocessor)\n",
        "model_4.fit(x=train_ds)\n",
        "\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Bx3Feyjb2o"
      },
      "source": [
        "The following example re-implements the same logic using TensorFlow Feature\n",
        "Columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnwe3sBt-yJk"
      },
      "outputs": [],
      "source": [
        "def g_to_kg(x):\n",
        "  return x / 1000\n",
        "\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"body_mass_g\", normalizer_fn=g_to_kg),\n",
        "    tf.feature_column.numeric_column(\"bill_length_mm\"),\n",
        "]\n",
        "\n",
        "preprocessing = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model_5 = tfdf.keras.RandomForestModel(preprocessing=preprocessing)\n",
        "model_5.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vif6gsAjfzv"
      },
      "source": [
        "## Training a regression model\n",
        "\n",
        "The previous example trains a classification model (TF-DF does not differentiate\n",
        "between binary classification and multi-class classification). In the next\n",
        "example, train a regression model on the\n",
        "[Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone). The\n",
        "objective of this dataset is to predict the number of shell's rings of an\n",
        "abalone.\n",
        "\n",
        "**Note:** The csv file is assembled by appending UCI's header and data files. No preprocessing was applied.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/LivingAbalone.JPG/800px-LivingAbalone.JPG\" width=\"200\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uKI_Uy7RyWN"
      },
      "outputs": [],
      "source": [
        "# Download the dataset.\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/abalone_raw.csv -O /tmp/abalone.csv\n",
        "\n",
        "dataset_df = pd.read_csv(\"/tmp/abalone.csv\")\n",
        "print(dataset_df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gjrquQySU7Q"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into a training and testing dataset.\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Name of the label column.\n",
        "label = \"Rings\"\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8fUhQKISqYT"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Configure the model.\n",
        "model_7 = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "# Train the model.\n",
        "model_7.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSriIAaMSzwA"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "model_7.compile(metrics=[\"mse\"])\n",
        "evaluation = model_7.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "print(evaluation)\n",
        "print()\n",
        "print(f\"MSE: {evaluation['mse']}\")\n",
        "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54mR6i9jkhp"
      },
      "source": [
        "## Training a ranking model\n",
        "\n",
        "Finally, after having trained a classification and a regression models, train a [ranking](https://en.wikipedia.org/wiki/Learning_to_rank) model.\n",
        "\n",
        "The goal of a ranking is to **order** items by importance. The \"value\" of\n",
        "relevance does not matter directly. Ranking a set of *documents* with regard to\n",
        "a user *query* is an example of ranking problem: It is only important to get the right order, where the top documents matter more.\n",
        "\n",
        "TF-DF expects for ranking datasets to be presented in a \"flat\" format. A\n",
        "document+query dataset might look like that:\n",
        "\n",
        "query | document_id | feature_1 | feature_2 | relevance/label\n",
        "----- | ----------- | --------- | --------- | ---------------\n",
        "cat   | 1           | 0.1       | blue      | 4\n",
        "cat   | 2           | 0.5       | green     | 1\n",
        "cat   | 3           | 0.2       | red       | 2\n",
        "dog   | 4           | NA        | red       | 0\n",
        "dog   | 5           | 0.2       | red       | 1\n",
        "dog   | 6           | 0.6       | green     | 1\n",
        "\n",
        "The *relevance/label* is a floating point numerical value between 0 and 5\n",
        "(generally between 0 and 4) where 0 means \"completely unrelated\", 4 means \"very\n",
        "relevant\" and 5 means \"the same as the query\".\n",
        "\n",
        "Interestingly, decision forests are often good rankers, and many\n",
        "state-of-the-art ranking models are decision forests.\n",
        "\n",
        "In this example, use a sample of the\n",
        "[LETOR3](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/#!letor-3-0)\n",
        "dataset. More precisely, we want to download the `OHSUMED.zip` from [the LETOR3 repo](https://onedrive.live.com/?authkey=%21ACnoZZSZVfHPJd0&id=8FEADC23D838BDA8%21107&cid=8FEADC23D838BDA8). This dataset is stored in the\n",
        "libsvm format, so we will need to convert it to csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axD6x1ZivHCS"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 200\n",
        "\n",
        "archive_path = tf.keras.utils.get_file(\"letor.zip\",\n",
        "  \"https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\",\n",
        "  extract=True)\n",
        "\n",
        "# Path to the train and test dataset using libsvm format.\n",
        "raw_dataset_path = os.path.join(os.path.dirname(archive_path),\"OHSUMED/Data/All/OHSUMED.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcManr98ZGID"
      },
      "source": [
        "The dataset is stored as a .txt file in a specific format, so first convert it into a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkiM9HJox-e8"
      },
      "outputs": [],
      "source": [
        "def convert_libsvm_to_csv(src_path, dst_path):\n",
        "  \"\"\"Converts a libsvm ranking dataset into a flat csv file.\n",
        "  \n",
        "  Note: This code is specific to the LETOR3 dataset.\n",
        "  \"\"\"\n",
        "  dst_handle = open(dst_path, \"w\")\n",
        "  first_line = True\n",
        "  for src_line in open(src_path,\"r\"):\n",
        "    # Note: The last 3 items are comments.\n",
        "    items = src_line.split(\" \")[:-3]\n",
        "    relevance = items[0]\n",
        "    group = items[1].split(\":\")[1]\n",
        "    features = [ item.split(\":\") for item in items[2:]]\n",
        "\n",
        "    if first_line:\n",
        "      # Csv header\n",
        "      dst_handle.write(\"relevance,group,\" + \",\".join([\"f_\" + feature[0] for feature in features]) + \"\\n\")\n",
        "      first_line = False\n",
        "    dst_handle.write(relevance + \",g_\" + group + \",\" + (\",\".join([feature[1] for feature in features])) + \"\\n\")\n",
        "  dst_handle.close()\n",
        "\n",
        "# Convert the dataset.\n",
        "csv_dataset_path=\"/tmp/ohsumed.csv\"\n",
        "convert_libsvm_to_csv(raw_dataset_path, csv_dataset_path)\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(csv_dataset_path)\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB7bWAja1G-o"
      },
      "outputs": [],
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Display the first 3 examples of the training dataset.\n",
        "train_ds_pd.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQKqN9zN4L00"
      },
      "source": [
        "In this dataset, the `relevance` defines the ground-truth rank among rows of the same `group`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QMbBkCEXxu_"
      },
      "outputs": [],
      "source": [
        "# Name of the relevance and grouping columns.\n",
        "relevance = \"relevance\"\n",
        "\n",
        "ranking_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n",
        "ranking_test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba1gb75SX1rr"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    task=tfdf.keras.Task.RANKING,\n",
        "    ranking_group=\"group\",\n",
        "    num_trees=50)\n",
        "\n",
        "model_8.fit(x=ranking_train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZCfxfR3VK0"
      },
      "source": [
        "At this point, keras does not propose any ranking metrics. Instead, the training and validation (a GBDT uses a validation dataset) are shown in the training\n",
        "logs. In this case the loss is `LAMBDA_MART_NDCG5`, and the final (i.e. at\n",
        "the end of the training) NDCG (normalized discounted cumulative gain) is `0.510136` (see line `Final model valid-loss: -0.510136`).\n",
        "\n",
        "Note that the NDCG is a value between 0 and 1. The larger the NDCG, the better\n",
        "the model. For this reason, the loss to be -NDCG.\n",
        "\n",
        "As before, the model can be analysed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4N1R8fM4jFh"
      },
      "outputs": [],
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}